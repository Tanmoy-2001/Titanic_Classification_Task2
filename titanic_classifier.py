# -*- coding: utf-8 -*-
"""Titanic Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NQUruRvdgQbpXBQUQM-_EMxjbxlkqTdS

**Step 1: Import Required Packages**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

"""**Step 2: Load and Explore the Data**"""

from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/MyDrive/Titanic_Dataset.csv"
df = pd.read_csv(path)

# Load the dataset
df = pd.read_csv('Titanic_Dataset.csv')

# Explore the data
print(df.head())  # View the first few rows
print(df.describe())  # Statistical summary of the data
print(df.info())  # Information about the columns and data types

"""**Step 3: Preprocess the Data**"""

# Handle missing values
df.fillna(df.mean(), inplace=True)  # Fill missing numerical values with the mean
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Fill missing categorical values with mode

# Convert categorical variables into numerical form
le = LabelEncoder()
df['Sex'] = le.fit_transform(df['Sex'])
df['Embarked'] = le.fit_transform(df['Embarked'])


# Select relevant features
features = ['Pclass', 'Sex', 'Age', 'sibsp', 'Parch']
X = df[features]

y = df['2urvived']

"""**Step 4: Split the Data into Training and Testing Sets**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Step 5: Train the Model**"""

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

"""**Step 6: Evaluate the Model**"""

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""**Step 7: Make Predictions**"""

new_data = pd.DataFrame([[3, 1, 25, 0, 1]], columns=['Pclass', 'Sex', 'Age', 'sibsp', 'Parch'])
prediction = model.predict(new_data)
print("Survival Prediction:", prediction)

"""**Model 2**"""

from xgboost.sklearn import XGBClassifier
model = XGBClassifier()
model.fit(X_train, y_train)

import xgboost as xgb

# Create an instance of the XGBoost classifier
model = xgb.XGBClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the testing data
y_pred = model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

new_data = pd.DataFrame([[3, 1, 25, 0, 1]], columns=['Pclass', 'Sex', 'Age', 'sibsp', 'Parch'])
prediction = model.predict(new_data)
print("Survival Prediction:", prediction)